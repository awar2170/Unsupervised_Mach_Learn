{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17.5.1\n",
    "### Overview of Support Vector Machines\n",
    "**Support vector machine (SVM)**, like logistic regression, is a binary classifier: It can categorize samples into one of two categories (for example, yes or no).\n",
    "\n",
    "To understand support vector machines, let's revisit logistic regression first. A logistic regression model evaluates the probability of an occurrence. For example, the model would take features into account (for example, an applicant's income and credit score) and decide whether to approve the application.\n",
    "\n",
    "The outcome is binary because the only possible options are to approve or to deny the loan application: If the probability is higher than 0.5, the application is classified as approved, or if the probability is less than that, the application is classified as denied. There is a strict cutoff line that divides one classification from the other:\n",
    "\n",
    "In logistic regression, a probability that exceeds 50% is classified one way, and all other values are classified as the other class.\n",
    "\n",
    "SVM also categorizes the target variable into one of two classes (for example, approved or denied). However, it differs from logistic regression in several ways. As a linear classifier, the goal of SVM is to find a line that separates the data into two classes:\n",
    "\n",
    "SVM is a binary classifier.\n",
    "\n",
    "However, there may be many different ways to draw the boundary line, as shown in the diagram below. Which boundary to choose isn't always clear from visual inspection, and choosing the wrong boundary can affect the performance of the model:\n",
    "\n",
    "A casual visual inspection of the data doesn't always make it clear how to optimally divide the classes.\n",
    "\n",
    "In a two-dimensional grid, as shown below, SVM draws a line at the edge of each class, and attempts to maximize the distance between them. It does so by separating the data points with the largest possible margins:\n",
    "\n",
    "SVM seeks to maximize the margins between the two classes\n",
    "\n",
    "A hyperplane is the line exactly between the two margins (i.e., equidistant from both margins). Again, the SVM's goal is to find the hyperplane with the widest possible margins (i.e., the largest margin of separation between the two classes):\n",
    "\n",
    "SVM seeks to find the widest equidistant margins to improve classification predictions.\n",
    "\n",
    "Support vectors are defined as the data points closest to the hyperplane:\n",
    "\n",
    "Support vectors are data points that define the class boundaries. Data points closest to the hyperplane are support vectors and serve as decision boundaries for classification.\n",
    "\n",
    "Real-life data, however, can be messy and will often not yield such a clean line of separation. Imagine that a data point belonging to the blue class were found closer to the cluster of data points that belong to the red class. In this case, would the hyperplane have to be relocated? Would the support vectors have to be redefined?\n",
    "\n",
    "TextSVMs can make exceptions for outliers with soft margins.: A data point is an outlier if it is close to a cluster of data points from another class.\n",
    "\n",
    "SVMs can accommodate such outliers by using soft margins. A soft margin allows SVM to make allowances for outliers that cross the hyperplane while maintaining support vectors and hyperplane to maximize the overall separation of the two classes:\n",
    "\n",
    "SVMs can make exceptions for outliers with soft margins.\n",
    "\n",
    "Up to this point, we have visualized using SVM in datasets with two features. A dataset with three features (e.g., age, education, income) and a target with two classes (e.g., approval or denial of a loan application) would be visualized as a 3D space, with a hyperplane separating the two classes:\n",
    "\n",
    "A 3D hyperplane separating two classes. Datasets with three features are modeled in 3D, with two target classes and a hyperplane.\n",
    "\n",
    "To summarize, SVM works by separating the two classes in a dataset with the widest possible margins. The margins, however, are soft and can make exceptions for outliers. This stands in contrast to the logistic regression model. In logistic regression, any data point whose probability of belonging to one class exceeds the cutoff point belongs to that class; all other data points belong to the other class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # SVM Loan Approver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " There are a number of classification algorithms that can be used to determine loan elgibility. Some algorithms run better than others. Build a loan approver using the SVM algorithm and compare the accuracy and performance of the SVM model with the Logistic Regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from path import Path\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>assets</th>\n",
       "      <th>liabilities</th>\n",
       "      <th>income</th>\n",
       "      <th>credit_score</th>\n",
       "      <th>mortgage</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.210859</td>\n",
       "      <td>0.452865</td>\n",
       "      <td>0.281367</td>\n",
       "      <td>0.628039</td>\n",
       "      <td>0.302682</td>\n",
       "      <td>deny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.395018</td>\n",
       "      <td>0.661153</td>\n",
       "      <td>0.330622</td>\n",
       "      <td>0.638439</td>\n",
       "      <td>0.502831</td>\n",
       "      <td>approve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.291186</td>\n",
       "      <td>0.593432</td>\n",
       "      <td>0.438436</td>\n",
       "      <td>0.434863</td>\n",
       "      <td>0.315574</td>\n",
       "      <td>approve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.458640</td>\n",
       "      <td>0.576156</td>\n",
       "      <td>0.744167</td>\n",
       "      <td>0.291324</td>\n",
       "      <td>0.394891</td>\n",
       "      <td>approve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.463470</td>\n",
       "      <td>0.292414</td>\n",
       "      <td>0.489887</td>\n",
       "      <td>0.811384</td>\n",
       "      <td>0.566605</td>\n",
       "      <td>approve</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     assets  liabilities    income  credit_score  mortgage   status\n",
       "0  0.210859     0.452865  0.281367      0.628039  0.302682     deny\n",
       "1  0.395018     0.661153  0.330622      0.638439  0.502831  approve\n",
       "2  0.291186     0.593432  0.438436      0.434863  0.315574  approve\n",
       "3  0.458640     0.576156  0.744167      0.291324  0.394891  approve\n",
       "4  0.463470     0.292414  0.489887      0.811384  0.566605  approve"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the data\n",
    "# Note: The following data has been normalized between 0 and 1\n",
    "data = Path('../Resources/loans.csv')\n",
    "df = pd.read_csv(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Separate the Features (X) from the Target (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segment the features from the target\n",
    "y = df[\"status\"]\n",
    "X = df.drop(columns=\"status\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Split our data into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the train_test_split function to create training and testing subsets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    random_state=1, \n",
    "                                                    stratify=y)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Create a SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a linear SVM model\n",
    "from sklearn.svm import SVC\n",
    "model = SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Fit (train) or model using the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the data\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Score the model using the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>approve</td>\n",
       "      <td>deny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>deny</td>\n",
       "      <td>approve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>deny</td>\n",
       "      <td>deny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>approve</td>\n",
       "      <td>deny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>deny</td>\n",
       "      <td>deny</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Prediction   Actual\n",
       "0    approve     deny\n",
       "1       deny  approve\n",
       "2       deny     deny\n",
       "3    approve     deny\n",
       "4       deny     deny"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions using the test data\n",
    "y_pred = model.predict(X_test)\n",
    "results = pd.DataFrame({\n",
    "    \"Prediction\": y_pred, \n",
    "    \"Actual\": y_test\n",
    "}).reset_index(drop=True)\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Generate Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7, 5],\n",
       "       [5, 8]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    from sklearn.metrics import confusion_matrix\n",
    "    confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Generate Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     approve       0.58      0.58      0.58        12\n",
      "        deny       0.62      0.62      0.62        13\n",
      "\n",
      "    accuracy                           0.60        25\n",
      "   macro avg       0.60      0.60      0.60        25\n",
      "weighted avg       0.60      0.60      0.60        25\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17.5.2\n",
    "### SVM in Practice\n",
    "Although the ideas behind support vector machines are different from those behind logistic regression, actually implementing a SVM model is very similar to what you have done. As before, you will split your dataset, create and train a model, create predictions, then validate the model.\n",
    "\n",
    "Now that we have looked at how an SVM model works, let's look at using SVM in practice. To get started, download the following files.\n",
    "\n",
    "Download 17-5-2-svm.zip (That is what is above here) \n",
    "\n",
    "Open the notebook and load the dataset:\n",
    "\n",
    "- from path import Path\n",
    "- import numpy as np\n",
    "- import pandas as pd\n",
    "\n",
    "- data = Path('../Resources/loans.csv')\n",
    "- df = pd.read_csv(data)\n",
    "- df.head()\n",
    "\n",
    "Each row in the dataset represents an application for a loan, and information is available on the applicant's assets, liabilities, income, credit score, and mortgage size. We also have information on whether the application was approved or denied. Here, the target variable is status, and all other columns are features used to predict the loan application status.\n",
    "\n",
    "It's worth noting that the data in this dataset have been normalized. In this case, the data in the numerical features, such as assets and liabilities, have been scaled to be between 0 and 1.\n",
    "\n",
    "We will discuss scaling in greater detail later, but note for now that some models require scaling the data, and that in this dataset, the scaling has been done for you:\n",
    "\n",
    "Preview of the dataset. The dataset shows the information for each loan application as well as status.\n",
    "\n",
    "The next two steps should be familiar. We separate the dataset into features (X) and target (y):\n",
    "\n",
    "- y = df[\"status\"]\n",
    "- X = df.drop(columns=\"status\")\n",
    "\n",
    "We then further split the dataset into training and testing sets. Note that the shape of the training is (75, 5), meaning 75 rows and five columns. It is generally good practice to stratify the data when splitting into training and testing sets, especially when the dataset is small, as is the case here:\n",
    "\n",
    "- from sklearn.model_selection import train_test_split\n",
    "- X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "   y,  random_state=1, stratify=y)\n",
    "- X_train.shape\n",
    "\n",
    "Next, we import the SVC module from Scikit-learn, then instantiate it. The kernel specifies the mathematical functions used to separate the classes. The kernel, in this example, identifies the orientation of the hyperplane as linear. However, a number of kernels exist that define nonlinear boundaries:\n",
    "\n",
    "- from sklearn.svm import SVC\n",
    "- model = SVC(kernel='linear')\n",
    "\n",
    "We then train the model with fit():\n",
    "\n",
    "- model.fit(X_train, y_train)\n",
    "\n",
    "Next, we create predictions with the model:\n",
    "\n",
    "- y_pred = model.predict(X_test)\n",
    "- results = pd.DataFrame({\n",
    "   \"Prediction\": y_pred,\n",
    "   \"Actual\": y_test\n",
    "- }).reset_index(drop=True)\n",
    "- results.head()\n",
    "\n",
    "We assess the accuracy_score of the model, which is 0.6:\n",
    "\n",
    "- from sklearn.metrics import accuracy_score\n",
    "- accuracy_score(y_test, y_pred)\n",
    "\n",
    "We then generate a confusion_matrix and print the classification report:\n",
    "\n",
    "- from sklearn.metrics import confusion_matrix\n",
    "- confusion_matrix(y_test, y_pred)\n",
    "\n",
    "- from sklearn.metrics import classification_report\n",
    "- print(classification_report(y_test, y_pred))\n",
    "\n",
    "The classification report calculates precision, recall (sensitivity), and the F1 score.\n",
    "\n",
    "In summary, much of using a SVM model in practice follows the pattern we saw with logistic regression: split the dataset, create a model, train the model, create predictions, then validate the model.\n",
    "\n",
    "skill drill\n",
    "\n",
    "Assess the performance of a logistic regression model, namely the precision, recall, and F1 scores for the approve category. Compare it with the performance of the SVM model. Which model performs better?\n",
    "End of text box.\n"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
