{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b51d90e8",
   "metadata": {},
   "source": [
    "17.3.2\n",
    "Logistic Regression to Predict Diabetes\n",
    "Now that you've gotten your feet wet with logistic regression, Jill believes that it's time to implement a model with a real dataset. In the next step, you will follow the familiar pattern as you instantiate a model, train it, create predictions, then validate the model.\n",
    "\n",
    "Let's solve another classification problem with logistic regression. This time, we'll use a dataset on diabetes among Pima Indian women.\n",
    "\n",
    "First, download the files you'll need.\n",
    "\n",
    "See the diabetes.ipynb file\n",
    "\n",
    "Open diabetes.ipynb. We can see from the preview of the DataFrame that multiple variables (also called features), such as the number of previous pregnancies, blood glucose level, and age, can be used to predict the outcome: whether a person has diabetes (1) or does not have diabetes (0):\n",
    "\n",
    "The first five rows of the Pima Indian diabetes dataset.\n",
    "\n",
    "####\n",
    "\n",
    "A common task in machine learning is data preparation. In previous examples, we assigned the label X to input variables, and used them to predict y, or the output. With this diabetes dataset, we need to categorize features from the target. We can do so by separating the Outcome column from the other columns.\n",
    "note\n",
    "\n",
    "The terms features and variables are synonymous. Target and output are synonymous.\n",
    "\n",
    "y = df[\"Outcome\"]\n",
    "X = df.drop(columns=\"Outcome\")\n",
    "\n",
    "    The Outcome column is defined as y, or the target.\n",
    "    X, or features, is created by dropping the Outcome column from the DataFrame.\n",
    "\n",
    "Later in this module, we'll be splitting the training and testing data, creating a logistic regression model, fitting the training data, and making a prediction. What steps can you do on your own in the following Skill Drills?\n",
    "\n",
    "Import the Scikit-learn module for logistic learning, and instantiate a model. Use the following arguments for the model:\n",
    "\n",
    "    solver='lbfgs'\n",
    "    max_iter=200 (this sets an upper limit on the number of iterations used by the solver)\n",
    "    random_state=1\n",
    "\n",
    "\n",
    "Let's retrace the steps taken so far. We first split the dataset into training and testing sets:\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "   y, random_state=1, stratify=y)\n",
    "\n",
    "Examining the shape of the training set with X_train.shape returned (576,8), meaning that there are 576 samples (rows) and eight features (columns).\n",
    "\n",
    "The next step was to create a logistic regression model with the specified arguments for solver, max_iter, and random_state:\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(solver='lbfgs',\n",
    "   max_iter=200,\n",
    "   random_state=1)\n",
    "\n",
    "Next, we trained the model with the training data:\n",
    "\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "To create predictions for y-values, we used the X_test set:\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "When the first 20 rows of the predicted y-values (y_pred) are compared with the actual y-values (y_test), we see that most of the predictions are correct, but that there are also some missed predictions, such as rows 14 and 15:\n",
    "\n",
    "The DataFrame shows predicted y-values and actual y-values. The majority of the predictions are correct.\n",
    "\n",
    "The final step is to answer an important question: how well does our logistic regression model predict? We do so with \n",
    "\n",
    "- sklearn.metrics.accuracy_score:\n",
    "\n",
    "- from sklearn.metrics import accuracy_score\n",
    "- print(accuracy_score(y_test, y_pred))\n",
    "\n",
    "This method compares the actual outcome (y) values from the test set against the model's predicted values. In other words, y_test are the outcomes (whether or not a woman has diabetes) from the original dataset that were set aside for testing. The model's predictions, y_pred, were compared with these actual values (y_test). The accuracy score is simply the percentage of predictions that are correct. In this case, the model's accuracy score was 0.776, meaning that the model was correct 77.6% of the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b9e61f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
