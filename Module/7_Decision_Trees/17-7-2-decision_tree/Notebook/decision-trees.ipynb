{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructor Do: Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial imports\n",
    "import pandas as pd\n",
    "from path import Path\n",
    "from sklearn import tree\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Preprocessing Loans Encoded Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amount</th>\n",
       "      <th>term</th>\n",
       "      <th>age</th>\n",
       "      <th>bad</th>\n",
       "      <th>month_num</th>\n",
       "      <th>education_Bachelor</th>\n",
       "      <th>education_High School or Below</th>\n",
       "      <th>education_Master or Above</th>\n",
       "      <th>education_college</th>\n",
       "      <th>gender_female</th>\n",
       "      <th>gender_male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>30</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>30</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "      <td>30</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "      <td>15</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1000</td>\n",
       "      <td>30</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   amount  term  age  bad  month_num  education_Bachelor  \\\n",
       "0    1000    30   45    0          6                   0   \n",
       "1    1000    30   50    0          7                   1   \n",
       "2    1000    30   33    0          8                   1   \n",
       "3    1000    15   27    0          9                   0   \n",
       "4    1000    30   28    0         10                   0   \n",
       "\n",
       "   education_High School or Below  education_Master or Above  \\\n",
       "0                               1                          0   \n",
       "1                               0                          0   \n",
       "2                               0                          0   \n",
       "3                               0                          0   \n",
       "4                               0                          0   \n",
       "\n",
       "   education_college  gender_female  gender_male  \n",
       "0                  0              0            1  \n",
       "1                  0              1            0  \n",
       "2                  0              1            0  \n",
       "3                  1              0            1  \n",
       "4                  1              1            0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading data\n",
    "file_path = Path(\"../Resources/loans_data_encoded.csv\")\n",
    "df_loans = pd.read_csv(file_path)\n",
    "df_loans.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amount</th>\n",
       "      <th>term</th>\n",
       "      <th>age</th>\n",
       "      <th>month_num</th>\n",
       "      <th>education_Bachelor</th>\n",
       "      <th>education_High School or Below</th>\n",
       "      <th>education_Master or Above</th>\n",
       "      <th>education_college</th>\n",
       "      <th>gender_female</th>\n",
       "      <th>gender_male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>30</td>\n",
       "      <td>45</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>30</td>\n",
       "      <td>50</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "      <td>30</td>\n",
       "      <td>33</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "      <td>15</td>\n",
       "      <td>27</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1000</td>\n",
       "      <td>30</td>\n",
       "      <td>28</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   amount  term  age  month_num  education_Bachelor  \\\n",
       "0    1000    30   45          6                   0   \n",
       "1    1000    30   50          7                   1   \n",
       "2    1000    30   33          8                   1   \n",
       "3    1000    15   27          9                   0   \n",
       "4    1000    30   28         10                   0   \n",
       "\n",
       "   education_High School or Below  education_Master or Above  \\\n",
       "0                               1                          0   \n",
       "1                               0                          0   \n",
       "2                               0                          0   \n",
       "3                               0                          0   \n",
       "4                               0                          0   \n",
       "\n",
       "   education_college  gender_female  gender_male  \n",
       "0                  0              0            1  \n",
       "1                  0              1            0  \n",
       "2                  0              1            0  \n",
       "3                  1              0            1  \n",
       "4                  1              1            0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define features set\n",
    "X = df_loans.copy()\n",
    "X = X.drop(\"bad\", axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define target vector\n",
    "y = df_loans[\"bad\"].values.reshape(-1, 1)\n",
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting into Train and Test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(375, 10)\n",
      "(125, 10)\n",
      "(375, 1)\n",
      "(125, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X, y, random_state=78, train_size=0.80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 10)\n",
      "(100, 10)\n",
      "(400, 1)\n",
      "(100, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train2.shape)\n",
    "print(X_test2.shape)\n",
    "print(y_train2.shape)\n",
    "print(y_test2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating StandardScaler instance\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting Standard Scaller\n",
    "X_scaler = scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the decision tree classifier instance\n",
    "model = tree.DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the model\n",
    "model = model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Predictions Using the Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions using the testing data\n",
    "predictions = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the confusion matrix\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"]\n",
    ")\n",
    "\n",
    "# Calculating the accuracy score\n",
    "acc_score = accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 0</th>\n",
       "      <th>Predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Actual 0</td>\n",
       "      <td>54</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Actual 1</td>\n",
       "      <td>23</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted 0  Predicted 1\n",
       "Actual 0           54           30\n",
       "Actual 1           23           18"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.576\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.64      0.67        84\n",
      "           1       0.38      0.44      0.40        41\n",
      "\n",
      "    accuracy                           0.58       125\n",
      "   macro avg       0.54      0.54      0.54       125\n",
      "weighted avg       0.59      0.58      0.58       125\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Displaying results\n",
    "print(\"Confusion Matrix\")\n",
    "display(cm_df)\n",
    "print(f\"Accuracy Score : {acc_score}\")\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17.7.2\n",
    "### Predict Loan Application Approval\n",
    "Now that you have learned how decision trees work, it's time to look at using a decision tree model in practice. You will first perform the data preprocessing steps.\n",
    "\n",
    "Let's try to predict loan application approvals using a decision tree on the loans_data_encoded.csv data we previously used to encode the dataset. Feel free to begin a new notebook, or to follow along the provided notebook.\n",
    "\n",
    "Download 17-7-2-decision_tree.zip (Links to an external site.) **THIS IS THE AOVE CODE** \n",
    "\n",
    "In Jupyter Notebook, import the following dependencies:\n",
    "\n",
    "    \"# Initial imports\"\n",
    "    import pandas as pd\n",
    "    from path import Path\n",
    "    from sklearn import tree\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "\n",
    "Next, read in your saved loans_data_encoded.csv file.\n",
    "\n",
    "    \"# Loading data\"\n",
    "    file_path = Path(\"../Resources/loans_data_encoded.csv\")\n",
    "    df_loans = pd.read_csv(file_path)\n",
    "    df_loans.head()\n",
    "\n",
    "The df_loans DataFrame displays 10 columns of features and one target (bad).\n",
    "\n",
    "Our goal is to predict if a loan application is worthy of approval based on information we have in our df_loans DataFrame. To do this, we'll have to split our dataset into features (or inputs) and target (or outputs). The features set, X, will be a copy of the df_loansDataFrame without the badcolumn. These features are all the variables that help determine whether a loan application should be denied.\n",
    "rewind\n",
    "\n",
    "Recall that X is the input data and y is the output data.\n",
    "\n",
    "    \"# Define the features set.\"\n",
    "    X = df_loans.copy()\n",
    "    X = X.drop(\"bad\", axis=1)\n",
    "    X.head()\n",
    "\n",
    "The output from the following code block will give us the following features set.\n",
    "\n",
    "The X DataFrame displays 10 columns of features and no target.\n",
    "\n",
    "The target set is the bad column, indicating whether or not a loan application is good (0) or bad (1). Run the following code to generate the target set data.\n",
    "\n",
    "    \"# Define the target set.\"\n",
    "    y = df_loans[\"bad\"].values\n",
    "    y[:5]\n",
    "\n",
    "A preview of the target set indicates five good (loan worthy) applications.\n",
    "\n",
    "    array([0, 0, 0, 0, 0])\n",
    "\n",
    "### Split the Data into Training and Testing Sets\n",
    "\n",
    "To train and validate our model, we'll need to split the features and target sets into training and testing sets. This will help determine the relationships between each feature in the features training set and the target training set, which we'll use to determine the validity of our model using the features and target testing sets.\n",
    "\n",
    "In Jupyter Notebook, add the following code that will split our data into training and testing sets.\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)\n",
    "\n",
    "When the train_test_split() function is executed, our data is split into a specific proportion of the original data sets. By default, our training and testing data sets are 75% and 25%, respectively, of the original data. Using the following code, we can see the data's 75-25 split.\n",
    "\n",
    "    \"# Determine the shape of our training and testing sets.\"\n",
    "    print(X_train.shape)\n",
    "    print(X_test.shape)\n",
    "    print(y_train.shape)\n",
    "    print(y_test.shape)\n",
    "\n",
    "The output from running the code above shows that the X_train and y_train is 75% of 500 and that the X_test and y_test are 25%.\n",
    "\n",
    "    (375, 10)\n",
    "    (125, 10)\n",
    "    (375, 1)\n",
    "    (125, 1)\n",
    "\n",
    "We can manually specify the desired split with the train_size parameter.\n",
    "\n",
    "    \"# Splitting into Train and Test sets into an 80/20 split.\"\n",
    "    X_train2, X_test2, y_train2, y_test2 = train_test_split(X, y, random_state=78, train_size=0.80)\n",
    "\n",
    "To see that the shape of our training and testing sets is a 80-20 split, we run the following code.\n",
    "\n",
    "    \"# Determine the shape of our training and testing sets.\"\n",
    "    print(X_train2.shape)\n",
    "    print(X_test2.shape)\n",
    "    print(y_train2.shape)\n",
    "    print(y_test2.shape)\n",
    "\n",
    "The output from this code will give the following results.\n",
    "\n",
    "    (400, 10)\n",
    "    (100, 10)\n",
    "    (400, 1)\n",
    "    (100, 1)\n",
    "\n",
    "**note**\n",
    "Consult the sklearn documentation for additional information about the train_test_split() (Links to an external site.) function and the parameters it takes.\n",
    "\n",
    "### Scale the Training and Testing Data\n",
    "\n",
    "Now that we have split our data into training and testing sets, we can scale the data using Scikit-learn's StandardScaler.\n",
    "rewind\n",
    "\n",
    "The standard scaler standardizes the data. Which means that each feature will be rescaled so that its mean is 0 and its standard deviation is 1.\n",
    "\n",
    "**note**\n",
    "Typically, models that compute distances between data points, such as SVM, require scaled data. Although decision trees don't require scaling the data, it can be helpful when comparing the performances of different models.\n",
    "\n",
    "To scale our data, we'll use the StandardScaler as before and fit the instance, scaler, with the training data and then scale the features with the transform() method:\n",
    "\n",
    "    \"# Creating a StandardScaler instance.\"\n",
    "    scaler = StandardScaler()\n",
    "    \"# Fitting the Standard Scaler with the training data.\"\n",
    "    X_scaler = scaler.fit(X_train)\n",
    "\n",
    "    \"# Scaling the data.\"\n",
    "    X_train_scaled = X_scaler.transform(X_train)\n",
    "    X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17.7.3\n",
    "#### Make Predictions and Evaluate Results\n",
    "Now that you have preprocessed your dataset, you can now turn your attention to using the decision tree model to make predictions and evaluate the results.\n",
    "\n",
    "**THIS IS FOR TEH REST OF THE ORIGINAL CODE ABOVE** \n",
    "\n",
    "### Fit the Decision Tree Model\n",
    "\n",
    "After scaling the features data, the decision tree model can be created and trained. First, we create the decision tree classifier instance and then we train or fit the \"model\" with the scaled training data.\n",
    "\n",
    "Add and run the following code block to create the decision tree instance and fit the model:\n",
    "\n",
    "    \"# Creating the decision tree classifier instance.\n",
    "    model = tree.DecisionTreeClassifier()\n",
    "    \"# Fitting the model.\n",
    "    model = model.fit(X_train_scaled, y_train)\n",
    "\n",
    "### Make Predictions Using the Testing Data\n",
    "\n",
    "After fitting the model, we can run the following code to make predictions using the scaled testing data:\n",
    "\n",
    "    \"# Making predictions using the testing data.\n",
    "    predictions = model.predict(X_test_scaled)\n",
    "\n",
    "The output from this code will be an array of 125 predictions with either a 1 for a bad loan application or a 0 for a good, or approved, loan application.\n",
    "\n",
    "Use model.predict() to display an array of predictions for bad or good loan applications.\n",
    "\n",
    "**note**\n",
    "Your predictions array may look different if you don't use the same seeding in the random_state parameter.\n",
    "\n",
    "### Evaluate the Model\n",
    "\n",
    "Finally, we'll determine how well our model classifies loan applications. First, we need to use a confusion matrix.\n",
    "\n",
    "The following code block creates the confusion_matrix using the y_test and the predictions that we just calculated and adds the confusion_matrix array to a DataFrame:\n",
    "\n",
    "    \"# Calculating the confusion matrix\n",
    "    cm = confusion_matrix(y_test, predictions)\n",
    "\n",
    "    \"# Create a DataFrame from the confusion matrix.\n",
    "    cm_df = pd.DataFrame(\n",
    "        cm, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"])\n",
    "\n",
    "    cm_df\n",
    "\n",
    "The confusion matrix in the DataFrame format.\n",
    "\n",
    "The results show that:\n",
    "\n",
    "    Out of 84 good loan applications (Actual 0), 50 were predicted to be good (Predicted 0), which we call true positives.\n",
    "    Out of 84 good loan applications (Actual 0), 34 were predicted to be bad (Predicted 1), which are considered false negatives.\n",
    "    Out of 41 bad loan applications (Actual 1), 22 were predicted to be good (Predicted 0) and are considered false positives.\n",
    "    Out of 41 bad loan applications (Actual 1), 19 were predicted to be bad (Predicted 1) and are considered true negatives.\n",
    "\n",
    "We can add these terms to the confusion matrix and add the row and column totals to get the following table:\n",
    "\n",
    "A table representation of the confusion matrix.\n",
    "\n",
    "Next, we can determine the accuracy, or how often the classifier is correct with the model, by running the following code:\n",
    "\n",
    "    \"# Calculating the accuracy score.\n",
    "    acc_score = accuracy_score(y_test, predictions)\n",
    "\n",
    "The accuracy of our model is 0.552, which can also be calculated as follows:\n",
    "\n",
    "    (True Positives (TP) + True Negatives (TN)) / Total = (50 + 19)/125 = 0.552\n",
    "\n",
    "Lastly, we can print out the above results along with the classification report, which will give us the precision, recall, F1 score, and support for the two classes.\n",
    "\n",
    "    \"# Displaying results\n",
    "    print(\"Confusion Matrix\")\n",
    "    display(cm_df)\n",
    "    print(f\"Accuracy Score : {acc_score}\")\n",
    "    print(\"Classification Report\")\n",
    "    print(classification_report(y_test, predictions))\n",
    "\n",
    "The print out of the confusion matrix, the accuracy score, and the classification report.\n",
    "\n",
    "Let's go over the results in the classification report:\n",
    "\n",
    "    **Precision:** Precision is the measure of how reliable a positive classification is. From our results, the precision for the good loan applications can be determined by the ratio TP/(TP + FP), which is 50/(50 + 22) = 0.69. The precision for the bad loan applications can be determined as follows: 19/(19 + 34) = 0.358. A low precision is indicative of a large number of false positives—of the 53 loan applications we predicted to be bad applications, 34 were actually good loan applications.\n",
    "    \n",
    "    **Recall:** Recall is the ability of the classifier to find all the positive samples. It can be determined by the ratio: TP/(TP + FN), or 50/(50 + 34) = 0.595 for the good loans and 19/(19 + 22) = 0.463 for the bad loans. A low recall is indicative of a large number of false negatives.\n",
    "    \n",
    "    **F1 score:** F1 score is a weighted average of the true positive rate (recall) and precision, where the best score is 1.0 and the worst is 0.0.\n",
    "    \n",
    "    **Support:** Support is the number of actual occurrences of the class in the specified dataset. For our results, there are 84 actual occurrences for the good loans and 41 actual occurrences for bad loans.\n",
    "\n",
    "In summary, this model may not be the best one for preventing fraudulent loan applications because the model's accuracy, 0.552, is low, and the precision and recall are not good enough to state that the model will be good at classifying fraudulent loan applications. Modeling is an iterative process: you may need more data, more cleaning, another model parameter, or a different model. It's also important to have a goal that's been agreed upon, so that you know when the model is good enough.\n",
    "note\n",
    "\n",
    "Consult the sklearn.metrics.precision_recall_fscore_support documentation (Links to an external site.) for additional information about the classification scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
